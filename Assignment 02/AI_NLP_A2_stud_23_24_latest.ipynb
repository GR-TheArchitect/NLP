{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cihj8t1AM00f"
      },
      "source": [
        "# Lab 2: Sequence Modeling and Parsing\n",
        "\n",
        "In this lab we will implement two very popular algorithms in NLP (and other applications). Both algorithms employ dynamic programming to find the optimal solution in an efficient way. The Viterbi algorithm for sequence modeling recovers the most likely sequence underlying the input sequence while the CKY algorithm finds all the possible ways to parse the input with a predefined grammar.  \n",
        "Let's dive into them...    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTkFjaarrc1F"
      },
      "source": [
        "# Rules\n",
        "* The assignment should submitted to **Blackboard** as `.ipynb`. Only **one submission per group**.\n",
        "\n",
        "* The **filename** should be the group number, e.g., `01.ipynb` or `31.ipynb`.\n",
        "\n",
        "* The questions marked **Extra** or **Optional** are an additional challenge for those interested in going the extra mile. There are no points for them.\n",
        "\n",
        "**Rules for implementation**\n",
        "\n",
        "* You should **write your code and answers in this iPython Notebook**. (See http://ipython.org/notebook.html for reference material.) If you have problems, please contact your teaching assistant.\n",
        "\n",
        "* Use only **one cell for code** and **one cell for markdown** answers!    \n",
        "\n",
        "    * Put all code in the cell with the `## YOUR CODE HERE ##` comment.\n",
        "    * Provide brief comments on what the code does at crucial points.\n",
        "    * For theoretical questions, put your solution in the `█████ YOUR ANSWER HERE █████` cell and keep the header.\n",
        "\n",
        "* Don't change or delete any initially provided cells, either text or code, unless explicitly instructed to do so.\n",
        "* Don't delete the comment lines `#TEST...` or edit their code cells.\n",
        "* Don't change the names of provided functions and variables or arguments of the functions.\n",
        "* Leave the output of your code in the output cells.\n",
        "* **Don't output unnecessary info** (e.g., printing variables for debugging purposes) or **add extra code cells** (e.g., for mounting your google drive). This clutters the notebook and slows down the grading.\n",
        "* Test your code and **make sure we can run your notebook** in the colab environment.\n",
        "* Don't forget to fill in the contribution information.\n",
        "\n",
        "<font color=\"red\">You following these rules helps us to grade the submissions relatively efficiently. If these rules are violated, a submission will be subject to penalty points.</font>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWqs-t7Grc1L"
      },
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "~~Delete this text and write instead of it your:~~\n",
        "* ~~a list of group members names (NOT student IDs)~~\n",
        "* ~~who contributed to which exercises (you don't need to be very detailed)~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUCfBV-9l7-"
      },
      "source": [
        "# General instructions\n",
        "\n",
        "Before diving into the exercises, keep in mind that the variables defined previously can be reused in the subsequent cells. So there is no need to redefine the same variable in multiple sections, e.g., it is sufficient to read the file in a variable once and later reuse the value of the variable, instead of re-reading the file.   \n",
        "\n",
        "If your code is too long and using several code cells instead of a single code cell. Rethink how to organize data in variables that you can easily access required info. Reading about [list comprehension](https://realpython.com/list-comprehension-python/#leverage-list-comprehensions) can be useful.\n",
        "\n",
        "Your code will often be evaluated based on its behaviour. So, during the grading some code cells are executed. If code runtime is too long than expected, this will hinder grading.\n",
        "\n",
        "<font color=\"red\">**The cases similar to the above-mentioned ones, will be subject to penalty points.**</font>\n",
        "\n",
        "<font color=\"red\">**Pay attention to test units**</font> that are either provided as assert cases or as comments. Test units help you by giving you a hint about a correct answer. Note that **passing test units doesn't guarantee the full points** for an execise because test units are incomplete and the code might fail on other test units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyN8CHaZiYZ4"
      },
      "source": [
        "# Part 1: Sequence Models\n",
        "\n",
        "In this lab, you will implement a **Hidden Markov Model (HMM)**. HMMs specify a **joint** probability over **observations** and **hidden states**.\n",
        "\n",
        "This is what we will do:\n",
        "\n",
        "1. **Estimate** a simple HMM model from training data (supervised learning)\n",
        "2. Find the *best* sequence of hidden states for a given sequence of observations (we define \"best\" in 2 different ways!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2bCocjNWhJe"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-hxVSot_94Q"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from collections import defaultdict, namedtuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYtiw-uliYZ9"
      },
      "source": [
        "## Notation\n",
        "\n",
        "$ \\Sigma := \\{ o_1, \\dots, o_J \\} $ is our set of **observations**\n",
        "\n",
        "$\\Lambda := \\{s_1, \\dots, s_K \\}$ is our set of **state labels**\n",
        "\n",
        "$\\Sigma^*$ are **all possible sequences** of observations (including empty string $\\epsilon$)\n",
        "\n",
        "$\\Lambda^*$ all possible sequences of hidden states (including empty string $\\epsilon$)\n",
        "\n",
        "> Extra info: we can say that $\\Sigma^*$ is the [Kleene-closure](https://en.wikipedia.org/wiki/Kleene_star) of $\\Sigma$, and $\\Lambda^*$ the Kleene-closure of $\\Lambda$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU2wjdGviYZ_"
      },
      "source": [
        "## A simple example: The Baby HMM\n",
        "\n",
        "We start with a simple example, so that we can easily verify that our code is correct.\n",
        "\n",
        "Consider that we are modeling how a baby behaves. We observe the baby doing the following things: laughing (`laugh`), crying (`cry`), and sleeping (`sleep`). This is our set $\\Sigma$ of **observations**.\n",
        "\n",
        "We presume that, at any moment, the baby can be either `hungry`, `bored`, or `happy`. Since babies cannot talk, each of these states is hidden. This is our set $\\Lambda$ of **hidden states**.\n",
        "\n",
        "**Now the question is: if we have a series of observations, can we predict what hidden states the baby went through?**\n",
        "\n",
        "To tackle this problem, we assume that the baby behaves like a **1st order discrete Markov chain**: the baby's current state only depends on its previous hidden state. The baby can be described as an HMM. (Yay!)\n",
        "\n",
        "For example, assume we observed the baby doing the following:\n",
        "\n",
        "```\n",
        "sleep cry laugh cry\n",
        "cry cry laugh sleep\n",
        "```\n",
        "\n",
        "We will use these sequences as our **test set**. We can try to find out the states of the baby for those observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRqiS7WiYaB"
      },
      "source": [
        "Now, to train our model, we will need some examples of **observations** and **states**; this is our **training set**:\n",
        "\n",
        "```\n",
        "laugh/happy cry/bored cry/hungry sleep/happy\n",
        "cry/bored laugh/happy cry/happy sleep/bored\n",
        "cry/hungry cry/bored sleep/happy\n",
        "```\n",
        "\n",
        "So we have **pairs** observation/state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RKaP-v_iYaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad542384-d12f-4e52-8a89-5b96d260cd8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set (observations):\n",
            "['sleep', 'cry', 'laugh', 'cry']\n",
            "['cry', 'cry', 'laugh', 'sleep']\n",
            "\n",
            "training set (observation/state pairs):\n",
            "[laugh/happy, cry/bored, cry/hungry, sleep/happy]\n",
            "[cry/bored, laugh/happy, cry/happy, sleep/bored]\n",
            "[cry/hungry, cry/bored, sleep/happy]\n"
          ]
        }
      ],
      "source": [
        "# read in test data\n",
        "test_data = \"\"\"sleep cry laugh cry\n",
        "cry cry laugh sleep\"\"\"\n",
        "\n",
        "def test_reader(test_lines):\n",
        "    for line in test_lines.splitlines():\n",
        "        yield line.split()\n",
        "\n",
        "test_set = list(test_reader(test_data))\n",
        "\n",
        "# read in train data\n",
        "train_data = \"\"\"laugh/happy cry/bored cry/hungry sleep/happy\n",
        "cry/bored laugh/happy cry/happy sleep/bored\n",
        "cry/hungry cry/bored sleep/happy\"\"\"\n",
        "\n",
        "# for convenience, we define a Observation-State pair class\n",
        "# fyi, more about namedtuple:\n",
        "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
        "Pair = namedtuple(\"Pair\", [\"obs\", \"state\"])\n",
        "Pair.__repr__ = lambda x: x.obs + \"/\" + x.state\n",
        "\n",
        "def train_reader(train_lines):\n",
        "    for line in train_data.splitlines():\n",
        "        # a pair is a string \"observation/state\" so we need to split on the \"/\"\n",
        "        yield [Pair(*pair.split(\"/\")) for pair in line.split()]\n",
        "\n",
        "training_set = list(train_reader(train_data))\n",
        "\n",
        "# print the results\n",
        "print(\"test set (observations):\")\n",
        "for seq in test_set:\n",
        "    print(seq)\n",
        "print(\"\\ntraining set (observation/state pairs):\")\n",
        "for seq in training_set:\n",
        "    print(seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ0zAoIgiYaF"
      },
      "source": [
        "## Vocabularies\n",
        "\n",
        "The `numpy` library is very practical when working with numeric vectors and matrices. Examples in this notebook heavily uses numpy arrays. It is recommended that you understand how simple arithmetic operation work on the arrays. You can also find very useful methods like `max` or `argmax` that will save several lines of code. You might find the following links useful: [NumPy Reference](https://numpy.org/doc/stable/reference/), [NumPy cheatsheets](https://blog.finxter.com/collection-10-best-numpy-cheat-sheets-every-python-coder-must-own/)\n",
        "\n",
        "It's going to be very useful if we can map states and observations to integers, so that we can identify them by a number. If we don't do this, then our implementation will be longer and much slower (This is relevant when we work with larger data, e.g. for POS tagging).\n",
        "\n",
        "Make sure you understand what is going on here: every time we look up an observation or state, the `defaultdict` will create a new key (index) if it has not seen that key (state or observation) before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AymV48GViYaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d969ccda-9997-41c0-98f6-8d274ee18c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Our vocabularies:\n",
            "defaultdict(<function <lambda> at 0x7f185c11eb90>, {'happy': 0, 'bored': 1, 'hungry': 2})\n",
            "defaultdict(<function <lambda> at 0x7f185c11edd0>, {'laugh': 0, 'cry': 1, 'sleep': 2})\n"
          ]
        }
      ],
      "source": [
        "# create mappings from state/obs to an ID\n",
        "state2i = defaultdict(lambda: len(state2i))\n",
        "obs2i = defaultdict(lambda: len(obs2i))\n",
        "\n",
        "for seq in training_set:\n",
        "    for example in seq:\n",
        "        _ = state2i[example.state]\n",
        "        _ = obs2i[example.obs]\n",
        "\n",
        "print(\"\\nOur vocabularies:\")\n",
        "print(state2i)\n",
        "print(obs2i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUdGcxmdiYaI"
      },
      "source": [
        "The HMM for the first training set sequence looks like this:\n",
        "\n",
        "![hmm-baby-train-1.png](data:image/png;base64,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)\n",
        "\n",
        "Now, we will **estimate** the following probability distributions:\n",
        "\n",
        "- initial: $P( s_k \\,|\\, \\texttt{start})$\n",
        "- transition: $P( s_k \\,|\\, s_l )$\n",
        "- final: $P(\\texttt{stop} \\,|\\, s_k )$\n",
        "- emission: $P( o_l \\,|\\, s_k)$\n",
        "\n",
        "These distributions are all we need. Remember that:\n",
        "\n",
        "- the probability of transitioning to a state $s_k$ only depends on one previous state $s_l$ (1st order Markov assumption).\n",
        "- emitting an observation $o_l$ only depends on the state $s_k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5GorW8viYaK"
      },
      "source": [
        "## Finding the Maximum Likelihood Parameters\n",
        "\n",
        "Now we would like to know what those distributions look like from our data. This is called **estimation**. Given our training data, we count how many times each event occurs and normalize the counts to form proper probability distributions.\n",
        "\n",
        "Let's first do counts for the start probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_NwY0mFiYaK",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2996c03-eedc-49bb-8e85-7d924861121d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# we can get the number of states and observations from our dictionaries\n",
        "num_states = len(state2i)\n",
        "num_observations = len(obs2i)\n",
        "\n",
        "# this creates a vector of length `num_states` filled with zeros\n",
        "counts_start = np.zeros(num_states)\n",
        "\n",
        "# now we count 1 every time a sequence starts with a certain state\n",
        "# we look up the index for the state that we want to count using the `state2i` dictionary\n",
        "for seq in training_set:\n",
        "    counts_start[state2i[seq[0].state]] += 1.\n",
        "\n",
        "print(counts_start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfaevoHniYaL"
      },
      "source": [
        "We see each state once at the beginning of a sequence in the training set, so that is why we have a count of 1 for each of them.\n",
        "\n",
        "We now **normalize** those counts, so that we obtain a probability distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2mR5lI-iYaM",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b30bbaf-eee2-4865-bc72-7c69a185aa58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start --> [0.33333333 0.33333333 0.33333333]\n"
          ]
        }
      ],
      "source": [
        "# since p_start is a numpy object, we can call sum on it; easy!\n",
        "total = counts_start.sum()\n",
        "\n",
        "# normalize: divide each count by the total\n",
        "p_start = counts_start / total\n",
        "print(f\"start --> {p_start}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpjkxRv2iYaM"
      },
      "source": [
        "We now turn to the **transition probabilities** and **stop probabilities**. We count, and then we normalize:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpYLqNmDiYaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9515d4-01fd-4940-ae2e-62a49677e30a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transition counts:\n",
            "[[1. 2. 1.]\n",
            " [2. 0. 1.]\n",
            " [0. 1. 0.]]\n",
            "Final counts:\n",
            "[2. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "# we can transition from any state to any other state in principle,\n",
        "# so we create a matrix filled with zeros so that we can count any pair of states\n",
        "# in practice, some transitions might not occur in the training data\n",
        "counts_trans = np.zeros((num_states, num_states))\n",
        "\n",
        "# for the final/stop probabilities, we only need to store `num_states` values.\n",
        "# so we use a vector\n",
        "counts_stop = np.zeros(num_states)\n",
        "\n",
        "# now we count transitions, one sequence at a time\n",
        "for seq in training_set:\n",
        "    for i in range(1, len(seq)):\n",
        "\n",
        "        # convert the states to indexes\n",
        "        prev_state = state2i[seq[i-1].state]\n",
        "        current_state = state2i[seq[i].state]\n",
        "\n",
        "        # count\n",
        "        counts_trans[current_state, prev_state] += 1.\n",
        "        # note that the order of states/indices in this matrix\n",
        "        # follows conditional probability order p(q_i|q_{i-1})\n",
        "        # not the transition matrix A_{i-1}_{i}\n",
        "\n",
        "# count final states\n",
        "for seq in training_set:\n",
        "    state = state2i[seq[-1].state]\n",
        "    counts_stop[state] += 1.\n",
        "\n",
        "# print the counts\n",
        "print(\"Transition counts:\")\n",
        "print(counts_trans)\n",
        "\n",
        "print(\"Final counts:\")\n",
        "print(counts_stop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZrxBHQHiYaO"
      },
      "source": [
        "Now we can normalize again. We will need to collect the total counts per state.\n",
        "Take some time to understand that the totals consist of the transition counts AND the final counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am85FysNiYaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c577d62d-4cc0-4aa0-ada9-9e36253cb472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3. 3. 2.]\n"
          ]
        }
      ],
      "source": [
        "# Useful trick: np.sum(m, 0) sums matrix m along the first dimension (with index 0).\n",
        "# Note that after summing the dimension disappears\n",
        "print(counts_trans.sum(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XsW6QSIiYaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc829a87-d1e1-42d5-d519-3f712c8f5ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total counts per state:\n",
            "[5. 4. 2.]\n",
            "\n",
            "Transition probabilities:\n",
            "[[0.2  0.5  0.5 ]\n",
            " [0.4  0.   0.5 ]\n",
            " [0.   0.25 0.  ]]\n",
            "\n",
            "Final probabilities:\n",
            "[0.4  0.25 0.  ]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_per_state = counts_trans.sum(0) + counts_stop\n",
        "print(f\"Total counts per state:\\n{total_per_state}\\n\")\n",
        "\n",
        "# now we normalize\n",
        "# here '/' works one column at a time in the matrix\n",
        "p_trans = counts_trans / total_per_state\n",
        "print(f\"Transition probabilities:\\n{p_trans}\\n\")\n",
        "\n",
        "# here '/' divides the values in each corresponding index in the 2 vectors\n",
        "p_stop = counts_stop / total_per_state\n",
        "print(f\"Final probabilities:\\n{p_stop}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1cikCNxiYaQ"
      },
      "source": [
        "**So far so good!** Now let's take care of **emission probabilities**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2UmIZEkiYaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92727128-1ef8-4dd9-bf3c-be605b180e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emission counts:\n",
            "[[2. 0. 0.]\n",
            " [1. 3. 2.]\n",
            " [2. 1. 0.]]\n",
            "\n",
            "p_emiss:\n",
            "[[0.4  0.   0.  ]\n",
            " [0.2  0.75 1.  ]\n",
            " [0.4  0.25 0.  ]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# now we create a matrix to keep track of emission counts\n",
        "# in principle any states can emit any observation\n",
        "# so we need a matrix again:\n",
        "# 1st dimension is for observations, 2nd is for states\n",
        "# the dim. order follows conditional probabilities p(o|s)\n",
        "counts_emiss = np.zeros((num_observations, num_states))\n",
        "\n",
        "# count\n",
        "for seq in training_set:\n",
        "    for obs, state in seq:\n",
        "        obs = obs2i[obs]\n",
        "        state = state2i[state]\n",
        "        counts_emiss[obs][state] += 1.\n",
        "\n",
        "# normalize\n",
        "p_emiss = counts_emiss / counts_emiss.sum(0)\n",
        "\n",
        "print(f\"emission counts:\\n{counts_emiss}\\n\")\n",
        "print(f\"p_emiss:\\n{p_emiss}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbgSVREVq-9m"
      },
      "source": [
        "This is a good moment for a sanity check. First, take a look at the training set to see if these probabilities are correct, i.e. check if  for each state $s_k$: $$\\sum_l P(s_l \\,|\\, s_k) = 1.0$$ Note that this includes transitions to \"stop\" state, so you have to take those into account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsBjY3dyiYaT"
      },
      "source": [
        "## Decoding a sequence\n",
        "\n",
        "Ok, so we have estimated a model. Great. Now what? Well, now we can **decode**!\n",
        "\n",
        "Given an observation sequence $o_1, o_2, \\dots, o_N$, we want to find the sequence of hidden states $s^* = s^*_1, s^*_2, \\dots, s^*_N$ that **best** explains those observations.\n",
        "\n",
        "But what does \"best\" mean?\n",
        "\n",
        "1. If we are interested in the best **global** assignment of states to the sequence as a whole, we can use the **Viterbi** algorithm.\n",
        "2. If we care more about minimizing the **local** error of getting each $s_i$ right, we can use **posterior decoding** (also called *max marginal decoding*).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQpYp-cCiYaU"
      },
      "source": [
        "### Decoding: The Viterbi Algorithm\n",
        "\n",
        "Viterbi gives us the best global hidden state sequence, i.e.:\n",
        "\n",
        "$$ \\begin{array}{lll}\n",
        "s^* &=& \\arg\\max_{s = s_1, s_2, \\dots, s_N} P(s_1, s_2, \\dots, s_N \\,|\\, o_1, o_2, \\dots, o_N ) \\\\\n",
        "    &=& \\arg\\max_{s = s_1, s_2, \\dots, s_N} P(s_1, s_2, \\dots, s_N, o_1, o_2, \\dots, o_N )\n",
        "\\end{array}$$\n",
        "\n",
        "To explain Viterbi we will make use of a **trellis**, a kind of graph that shows us the possible states for each time step.\n",
        "\n",
        "For our earlier example, the trellis looks like this:\n",
        "\n",
        "![hmm-baby-train-1-trellis.png](data:image/png;base64,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)\n",
        "\n",
        "Note, that we can now label the edges of this trellis with the following probabilities:\n",
        "\n",
        "- $P_{\\text start}(s_k \\,|\\, \\text{start})$ on the three edges from \"start\"\n",
        "- $P_{\\text stop}(\\text{stop} \\,|\\, s_k)$ on the three edges leading to \"stop\"\n",
        "- $P_{\\text trans}(s_k \\,|\\, s_{l})$ on each remaining edge from state $s_l$ to $s_k$\n",
        "- $P_{\\text emiss}(o \\,|\\, s_k)$ from each state $s_k$, to an observation $o$ made from that state (not shown here)\n",
        "\n",
        "Do you see that our trellis nicely shows the independence assumptions of the HMM?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8qPpkVjiYaU"
      },
      "source": [
        "### A Naive approach to get the best sequence\n",
        "\n",
        "To see why the Viterbi algorithm is so useful, we can consider another way to calculate $s^*$:\n",
        "\n",
        "- Iterate over all possible state sequences (all ways to go from `start` to `stop`)\n",
        "    - Calculate the probability for that sequence\n",
        "    - Store the highest probability seen so far and its sequence\n",
        "- Return the sequence that had the maximum probability\n",
        "\n",
        "The problem with this approach is that there are a lot of possible sequences!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "CxfZN2UxiYaV"
      },
      "source": [
        "## The Viterbi algorithm\n",
        "\n",
        "*We use a slightly different notation here compared to the lecture.*\n",
        "\n",
        "So how do we find the path with the highest score? The idea is that we can use our trellis to represent an **exponential number of paths**. Since we are only interested in the highest-scoring path, for every state at every time step, we only need to keep track of the **highest** probability that can lead us to that state. We can disregard any other paths that lead to that state, since they will for sure not be part of the highest-scoring path.\n",
        "\n",
        "Viterbi uses **dynamic programming**. Here, that means that we will re-use probabilities that we have already computed, so we never have to compute the score for the same sub-problem multiple times.\n",
        "\n",
        "Let's start at the beginning.\n",
        "\n",
        "For the first time step, the **viterbi score** is the transition probability of reaching a state $s_k$ from \"start\", times the probability of emitting the first observation $o_1$ from that state:\n",
        "\n",
        "$$\\text{viterbi}(1, s_k) = P_{\\text start}( s_k \\,|\\, \\text{start}) \\times P_{\\text emiss}(o_1 \\,|\\, s_k)$$\n",
        "\n",
        "So, the Viterbi trellis represents the path with maximum probability in position $i$ when we are in state $y_i$ having observed $o_1, o_2, \\dots, o_i$, the observations up to and including that point.\n",
        "\n",
        "Now that we have the viterbi scores for all states of the first time step in our trellis, we can use the following **recursive formula** to get the scores for all other states, one time step at a time:\n",
        "\n",
        "$$\\text{viterbi}(i, s_k) = \\big( \\max_{s_l \\in \\Lambda} P_{\\text trans}(s_k | s_l) \\times \\text{viterbi}(i-1, s_l) \\big) \\times P_{\\text emiss}(o_i \\,|\\, s_k)$$\n",
        "\n",
        "Finally, for our final state \"stop\" we need to do something special, since there is no observation there:\n",
        "\n",
        "$$\\text{viterbi}(N+1, \\text{stop}) = \\max_{s_l \\in \\Lambda} P_{\\text stop}(\\text{stop} \\,|\\, s_l) \\times \\text{viterbi}(i-1, s_l)  $$\n",
        "\n",
        "This is all we need to know what probability the highest scoring path has! Do you see how the dynamic programming helps us to solve this task efficiently?\n",
        "\n",
        "## How did we get here?\n",
        "\n",
        "Once we reach the \"stop\" state we know the maximum probability, but we forgot how we got there! If you don't see this immediately, remember that, whenever we computed the viterbi score for a state, we took the maximum over all previous states' viterbi scores, times the transition from those states. But we didn't keep track of which state was actually selected in that \"max\" operation. So now that we are in \"stop\", we don't know how we got there.\n",
        "\n",
        "To solve this, we will use **backpointers**. Whenever we do a $\\max$, we store what state was selected by that max (i.e. the $\\arg\\max$):\n",
        "\n",
        "$$\\text{backtrack}(i, s_k) = \\arg\\max_{s_l \\in \\Lambda} P_{\\text trans}(s_k | s_l) \\times \\text{viterbi}(i-1, s_l)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFlBQv_74cbW"
      },
      "source": [
        "## From probabilities to log-probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "AGEiDOw0iYaW"
      },
      "source": [
        "Now you know enough to implement Viterbi! But before we start...  \n",
        "Because probabilities tend to get rather small when multiplying, causing numerical instabilities, we will use **log probabilities**. This means that, instead of multiplying, we can now **sum** probabilities, because:\n",
        "\n",
        "$$ \\log(uv) = \\log u + \\log v$$\n",
        "\n",
        "To get the probability of a  path trough our trellis from \"start\" to \"stop\", we can just **sum** the log-probabilities that we encounter. So, finding the best (\"Viterbi\") path means finding the path with the **highest score**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flA1qns5iYaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d15e255-c07a-43f6-920b-d5a1fa46970d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "[0.33333333 0.33333333 0.33333333]\n",
            "[[0.2  0.5  0.5 ]\n",
            " [0.4  0.   0.5 ]\n",
            " [0.   0.25 0.  ]]\n",
            "[0.4  0.25 0.  ]\n",
            "[[0.4  0.   0.  ]\n",
            " [0.2  0.75 1.  ]\n",
            " [0.4  0.25 0.  ]]\n",
            "After:\n",
            "[-1.09861229 -1.09861229 -1.09861229]\n",
            "[[-1.60943791 -0.69314718 -0.69314718]\n",
            " [-0.91629073        -inf -0.69314718]\n",
            " [       -inf -1.38629436        -inf]]\n",
            "[-0.91629073 -1.38629436        -inf]\n",
            "[[-0.91629073        -inf        -inf]\n",
            " [-1.60943791 -0.28768207  0.        ]\n",
            " [-0.91629073 -1.38629436        -inf]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-77e2f4085654>:5: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.log(p_start), np.log(p_trans), np.log(p_stop), np.log(p_emiss)\n"
          ]
        }
      ],
      "source": [
        "def convert_to_log(p_start=None, p_trans=None, p_stop=None, p_emiss=None):\n",
        "    \"\"\"\n",
        "    Convert all probabilities to log-probabilities\n",
        "    \"\"\"\n",
        "    return np.log(p_start), np.log(p_trans), np.log(p_stop), np.log(p_emiss)\n",
        "\n",
        "print(f\"Before:\\n{p_start}\\n{p_trans}\\n{p_stop}\\n{p_emiss}\")\n",
        "\n",
        "# do the conversion\n",
        "lp_start, lp_trans, lp_stop, lp_emiss = \\\n",
        "    convert_to_log(p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
        "\n",
        "print(f\"After:\\n{lp_start}\\n{lp_trans}\\n{lp_stop}\\n{lp_emiss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHdqKIKgiYaY"
      },
      "source": [
        "## Smoothing\n",
        "\n",
        "Some probabilities were 0.0, and the log function is not defined for zero, resulting in a **warning** or `-inf` (depending on your numpy version).\n",
        "\n",
        "To prevent this, we can add a small **smoothing** value to our **counts**, so that we never have a probability of zero.\n",
        "\n",
        "To make things easier, we define a `normalize_all` function below that does all the normalization again,\n",
        "but now adding a small value to all the counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr6sZmlpiYaY"
      },
      "outputs": [],
      "source": [
        "def normalize(x, smoothing=0.1, axis=0):\n",
        "    smoothed = x + smoothing\n",
        "    return smoothed / smoothed.sum(axis)\n",
        "\n",
        "def normalize_all(counts_start, counts_trans, counts_stop, counts_emiss, smoothing=0.1):\n",
        "    \"\"\"Normalize all counts to probabilities, optionally with smoothing.\"\"\"\n",
        "    p_start = normalize(counts_start, smoothing=smoothing)\n",
        "    p_emiss = normalize(counts_emiss, smoothing=smoothing)\n",
        "\n",
        "    counts_trans_smoothed = counts_trans + smoothing\n",
        "    counts_stop_smoothed = counts_stop + smoothing\n",
        "    total_trans_stop = counts_trans_smoothed.sum(0) + counts_stop_smoothed\n",
        "    p_trans = counts_trans_smoothed / total_trans_stop\n",
        "    p_stop = counts_stop_smoothed / total_trans_stop\n",
        "\n",
        "    return p_start, p_trans, p_stop, p_emiss\n",
        "\n",
        "\n",
        "# normalize with smoothing\n",
        "smoothing = 0.1\n",
        "p_start, p_trans, p_stop, p_emiss = normalize_all(\n",
        "    counts_start, counts_trans, counts_stop, counts_emiss, smoothing=smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDTTwycPGncZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf0eb2a-c89c-4346-e56d-78b40d1c947e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoothed probabilities:\n",
            "[0.33333333 0.33333333 0.33333333]\n",
            "[[0.2037037  0.47727273 0.45833333]\n",
            " [0.38888889 0.02272727 0.45833333]\n",
            " [0.01851852 0.25       0.04166667]]\n",
            "[0.38888889 0.25       0.04166667]\n",
            "[[0.39622642 0.02325581 0.04347826]\n",
            " [0.20754717 0.72093023 0.91304348]\n",
            " [0.39622642 0.25581395 0.04347826]]\n",
            "Smoothed log-probabilities:\n",
            "[-1.09861229 -1.09861229 -1.09861229]\n",
            "[[-1.59108877 -0.7396672  -0.78015856]\n",
            " [-0.94446161 -3.78418963 -0.78015856]\n",
            " [-3.98898405 -1.38629436 -3.17805383]]\n",
            "[-0.94446161 -1.38629436 -3.17805383]\n",
            "[[-0.92576948 -3.76120012 -3.13549422]\n",
            " [-1.57239664 -0.32721291 -0.09097178]\n",
            " [-0.92576948 -1.36330484 -3.13549422]]\n"
          ]
        }
      ],
      "source": [
        "# convert to log-probabilities\n",
        "print(f\"Smoothed probabilities:\\n{p_start}\\n{p_trans}\\n{p_stop}\\n{p_emiss}\")\n",
        "\n",
        "lp_start, lp_trans, lp_stop, lp_emiss = convert_to_log(p_start=p_start, p_trans=p_trans, p_stop=p_stop, p_emiss=p_emiss)\n",
        "print(f\"Smoothed log-probabilities:\\n{lp_start}\\n{lp_trans}\\n{lp_stop}\\n{lp_emiss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11sJAepliYaa"
      },
      "source": [
        "## Ex1 [40pt] Implement the Viterbi algorithm\n",
        "\n",
        "You will now implement the Viterbi algorithm. Complete the function `viterbi(sequence, p_start, p_trans, p_emiss, p_stop)` below.\n",
        "\n",
        "**Input:** sequence ($o_1, ..., o_N$), $P_\\text{start}$, $P_\\text{trans}$, $P_\\text{emiss}$, $P_\\text{stop}$\n",
        "\n",
        "*Forward pass: compute the best path for every end state*\n",
        "\n",
        "- set $\\text{viterbi}(1, s_k)$ for each $s_k$\n",
        "- for $i=2$ to $N$, and for each $s_k$, set $\\text{viterbi}(i, s_k$) and $\\text{backtrack}(i, s_k)$\n",
        "- $\\text{max_prob} = \\max_{s_l} P_{\\text{stop}}(\\text{stop} \\,|\\, s_l) \\times viterbi(N, s_l)$\n",
        "\n",
        "*Backward pass: backtrack to get most likely path*\n",
        "- $\\hat{s}_N = \\arg\\max_{s_l} P_\\text{stop}(\\text{stop} \\,|\\, s_l) \\times viterbi(N, s_l)$\n",
        "- for $i = N-1$ to $1$: $\\hat{s}_i = \\text{backtrack}(i+1, \\hat{s}_{i+1})$\n",
        "\n",
        "**Output:** max_prob, Viterbi path $\\hat{s}_1, \\hat{s}_2, \\dots, \\hat{s}_N$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AoL2DI2iYaa"
      },
      "outputs": [],
      "source": [
        "def viterbi(sequence, lp_start=None, lp_trans=None, lp_stop=None, lp_emiss=None):\n",
        "    \"\"\"\n",
        "    Compute the Viterbi sequence.\n",
        "    Note: you have to use log-probabilities!\n",
        "\n",
        "    The return value should be a tuple (max_prob, list_of_viterbi_states)\n",
        "    Return:\n",
        "      - best_score (float) the log-probability of the best path\n",
        "      - best_path (int list) the best path as a list of state IDs\n",
        "    \"\"\"\n",
        "\n",
        "    length = len(sequence)\n",
        "    num_states = len(lp_start)\n",
        "\n",
        "    # trellis to store Viterbi scores\n",
        "    # we store -inf as our initial scores since log(0)=-inf\n",
        "    trellis = np.full([length, num_states], -np.inf)\n",
        "\n",
        "    # backpointers to backtrack (to remember what prev. state caused the maximum score)\n",
        "    # we initialize with -1 values, to represent a non-existing index\n",
        "    backpointers = -np.ones([length, num_states], dtype=int)\n",
        "\n",
        "    # YOUR CODE HERE [we tested the code by computing the results by hand. It works]\n",
        "\n",
        "#step 1: set viterbi(1,s_k) for each s_k: viterbi(1,s_k)=P[start](s_k|start)×P[emiss](o1|s_k)\n",
        "    #since we're using log-probabilities, multiplication goes to adddition.\n",
        "    #we populate the Viterbi scores of the start states.\n",
        "\n",
        "    trellis[0] = lp_start + lp_emiss[obs2i[sequence[0]],:]\n",
        "\n",
        "#step 2: for each s_k compute viterbi(i,s_k) for i=(2 to N) and store the backtrack(i,s_k)\n",
        "    #viterbi(i,s_k)=(max[s_l∈Λ]Ptrans(s_k|s_l)×viterbi(i−1,s_l))×Pemiss(oi|s_k)\n",
        "\n",
        "    for sequence_point in range(1, length):\n",
        "      for state in range(num_states):\n",
        "        #compute (P[trans](s_k|s_l) × viterbi(i−1,s_l)).\n",
        "        log_viterbi = trellis[sequence_point - 1] + lp_trans[state, :]\n",
        "        #compute the Viterbi score by taking the max of log_viterbi and adding the log of P[emiss](oi|s_k)\n",
        "        trellis[sequence_point, state] = np.max(log_viterbi) + lp_emiss[obs2i[sequence[sequence_point]], state]\n",
        "        #back track: output the indices of the maximum log_viterbi which identify the states\n",
        "        backpointers[sequence_point, state] = np.argmax(log_viterbi)\n",
        "\n",
        "#step 3: compute max_prob=max[s_l] (Pstop(stop|s_l)×viterbi(N,s_l))\n",
        "\n",
        "    max_prob = trellis[-1] + lp_stop\n",
        "    best_score = np.max(max_prob)\n",
        "\n",
        "#step 4: backtrack to get most likely path\n",
        "    best_path = []\n",
        "    best_path.append(np.argmax(max_prob))\n",
        "    for path in range(length - 1, 0, -1):\n",
        "      best_path.append(backpointers[path, best_path[-1]])\n",
        "    best_path.reverse()\n",
        "\n",
        "    return best_score, best_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFKQ-RPEiYab"
      },
      "source": [
        "## Trying out Viterbi\n",
        "\n",
        "Once you have implemented the Viterbi algorithm, try it out on the following sequence.\n",
        "\n",
        "Note: to get all points, make sure that the cell below runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwfGXoDriYab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5760c48b-9efa-454a-b0d7-68830ce431a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation= ['sleep', 'cry', 'laugh', 'cry']\n",
            "-7.619461837738772\n",
            "best state sequence= [0, 1, 0, 1]\n",
            "['happy', 'bored', 'happy', 'bored']\n"
          ]
        }
      ],
      "source": [
        "# TEST 1.1\n",
        "# Test out your Viterbi-algorithm here\n",
        "\n",
        "test_sequence = test_set[0]\n",
        "best_score, best_path = viterbi(test_sequence, lp_start=lp_start, lp_trans=lp_trans, lp_stop=lp_stop, lp_emiss=lp_emiss)\n",
        "\n",
        "print(\"observation=\", test_sequence)\n",
        "print(best_score)\n",
        "print(\"best state sequence=\", best_path)\n",
        "\n",
        "i2state = {v : k for k, v in state2i.items()}\n",
        "print([i2state[i] for i in best_path])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_codXTgCGLZ"
      },
      "source": [
        "# Part 2: Constituency parsing with CKY\n",
        "\n",
        "The grammatical structure of a sentence can be represented with a Context Free Grammar (CFG). When we additionally assign probabilities to the rules of the CFG we get a PCFG: a _Probabilistic_ CFG.\n",
        "\n",
        "Given a sufficiently expressive PCFG (one that holds enough rules) we can parse new sentences using the Cocke–Kasami–Younger (CKY) algorithm. You can use this algorithm in three ways: to find the set of all the possible parses $p$ of a sentence $s$ under a PCFG $G$; to find the probability of the sentence by summing up the probabilities of these parses; or to find the parse $p^{*}$ of the highest probability.\n",
        "\n",
        "\n",
        "### Tasks\n",
        "1. In this notebook you will learn how to represent a PCFG in an object-oriented manner as a collection of python classes. These classes are already defined for you. Read them through thoroughly and make sure that you understand them well. You have to use them in task 2.\n",
        "\n",
        "2. Implement the CKY algorithm to find the most probable parse $p^{*}$ for a sentence. Your implementation will follow the psuedo-code that is given in both the lecture slides, and Jurafsky and Martin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J__sR-Swbg_1"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2rFTz2rCGLd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "# nltk will be used to draw constituency parses\n",
        "import nltk\n",
        "from nltk.tree import Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5N77nlCWcvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704f8224-d18e-4a93-d6c3-880a2ee06cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-17 08:35:33 URL:https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-1.txt [337/337] -> \"groucho-grammar-1.txt\" [1]\n",
            "2024-05-17 08:35:34 URL:https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-2.txt [337/337] -> \"groucho-grammar-2.txt\" [1]\n",
            "2024-05-17 08:35:34 URL:https://naturallogic.pro/_files_/download/mNLP/telescope-grammar.txt [381/381] -> \"telescope-grammar.txt\" [1]\n"
          ]
        }
      ],
      "source": [
        "# downloading grammar files\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-1.txt\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-2.txt\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/telescope-grammar.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7SNulWbMf5"
      },
      "source": [
        "## PCFG\n",
        "\n",
        "In this lab we will show you a way to represent a **PCFG** using python objects. We will introduce the following classes:\n",
        "\n",
        "* Symbol\n",
        "    * Terminal\n",
        "    * Nonterminal\n",
        "* Rule\n",
        "\n",
        "At first glance, this might seem like a lot of work. But, hopefully, by the time you get to implementing CKY you will be convinced in the benefits of these constructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X2Nk5i3CGLg"
      },
      "source": [
        "### Symbol\n",
        "\n",
        "Recall that:\n",
        "* **Terminal** symbols are the words of the sentence: _I, ate, salad, the_ etc.\n",
        "* **Nonterminal** symbols are the syntactic categories of the various constituents: _S, NP, VP, Det_ etc.\n",
        "\n",
        "In our representation, `Symbol` is going to be a container class. The classes `Terminal` and `Nonterminal` will *inherit* from the `Symbol` class and will hence both become a type of symbol. The classes themselves are effectively a container for the underlying python strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlsXWvTjCGLh"
      },
      "outputs": [],
      "source": [
        "class Symbol:\n",
        "    \"\"\"\n",
        "    A symbol in a grammar.\n",
        "    This class will be used as parent class for Terminal, Nonterminal.\n",
        "    This way both will be a type of Symbol.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Terminal(Symbol):\n",
        "    \"\"\"\n",
        "    Terminal symbols are words in a vocabulary\n",
        "\n",
        "    E.g. 'I', 'ate', 'salad', 'the'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol: str):\n",
        "        assert type(symbol) is str, f\"A Terminal takes a python string, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return True\n",
        "\n",
        "    def is_nonterminal(self):\n",
        "        return False\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"'{self._symbol}'\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Terminal({repr(self._symbol)})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self._symbol)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"The length of the underlying python string\"\"\"\n",
        "        return len(self._symbol)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self._symbol < other._symbol\n",
        "\n",
        "    @property\n",
        "    def obj(self):\n",
        "        \"\"\"Returns the underlying python string\"\"\"\n",
        "        return self._symbol\n",
        "\n",
        "\n",
        "class Nonterminal(Symbol):\n",
        "    \"\"\"\n",
        "    Nonterminal symbols are the grammatical classes in a grammar.\n",
        "\n",
        "    E.g. S, NP, VP, N, Det, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol: str):\n",
        "        assert type(symbol) is str, f\"A Nonterminal takes a python string, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return False\n",
        "\n",
        "    def is_nonterminal(self):\n",
        "        return True\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"[{self._symbol}]\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Nonterminal({repr(self._symbol)})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self._symbol)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"The length of the underlying python string\"\"\"\n",
        "        return len(self._symbol)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self._symbol < other._symbol\n",
        "\n",
        "    @property\n",
        "    def obj(self):\n",
        "        \"\"\"Returns the underlying python string\"\"\"\n",
        "        return self._symbol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ0WmVOZCGLj"
      },
      "source": [
        "Let's try out the classes by initializing some terminal and nonterminal symbols:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv2qVwloCGLk"
      },
      "outputs": [],
      "source": [
        "dog = Terminal('dog')\n",
        "the = Terminal('the')\n",
        "walks = Terminal('walks')\n",
        "\n",
        "S = Nonterminal('S')\n",
        "NP = Nonterminal('NP')\n",
        "NP_prime = Nonterminal('NP')\n",
        "VP = Nonterminal('VP')\n",
        "V = Nonterminal('V')\n",
        "N = Nonterminal('N')\n",
        "Det = Nonterminal('Det')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGZHKNAUCGLl"
      },
      "source": [
        "The methods `__eq__` and `__ne__` make it possible to compare our objects using standard Python syntax. But more importantly: compare in the way that we are interested in, namely whether the underlying representation is the same.\n",
        "\n",
        "To see the difference, try commenting out the method `__eq__` in the class above, and notice the different result of the equality test `NP==NP_prime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKWBrXghCGLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc6de9d-aad2-4baf-8d2d-3979312041e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'dog'\n",
            "[NP]\n",
            "\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(dog)\n",
        "print(NP)\n",
        "print()\n",
        "print(NP==Det)\n",
        "print(NP!=Det)\n",
        "print(NP==NP)\n",
        "print(NP==NP_prime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qScfOAVvCGLm"
      },
      "source": [
        "Note the difference between calling `print(NP)` and simply calling `NP`. The first is taken care of by the method `__str__` and the second by the method `__repr__`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTS_97wYCGLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b39ea7d-0fa6-496f-f0b4-100b0e60e502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Terminal('dog')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXMlXaFkCGLo"
      },
      "source": [
        "We can also easily check if our symbol is a terminal or not:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMuoMVHQCGLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461bac65-0c6f-4fa6-f77a-15f31a10896d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dog.is_terminal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtnXm0IUCGLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0705e0b9-0139-4d5b-d4e6-07cf759f23e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "NP.is_terminal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvtkwhBhCGLq"
      },
      "source": [
        "Finally the method `__hash__` makes our object *hashable*, and hence usable in a datastructure like a dictionary.\n",
        "\n",
        "Try commenting out this method above in the class and then retry constructing the dictionary: notice the error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nniQ14QyCGLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5e97c8-fab4-434f-b814-6aac9df20e63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Nonterminal('NP'): 1, Nonterminal('S'): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "d = {NP: 1, S: 2}\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpC5JyBcCGLs"
      },
      "source": [
        "### Rules\n",
        "\n",
        "In a PCFG a **rule** looks something like this\n",
        "\n",
        "$$NP \\to Det\\;N$$\n",
        "\n",
        "with a corresponding probability, for example $1.0$ if we lived in a world where all noun phrases had this grammatical structure.\n",
        "\n",
        "In our representation, `Rule` will be an object made of a left-hand side (`lhs`) symbol, a sequence of right-hand side symbols (`rhs`) and a probability `prob`.\n",
        "\n",
        "If we use the above defined symbols, we can call\n",
        "\n",
        "    rule = Rule(NP, [Det, N], 1.0)\n",
        "   \n",
        "This will construct an instance called `rule` which represent the rule above\n",
        "\n",
        "    [NP] -> [Det] [N] (1.0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXN4G4t-CGLs"
      },
      "outputs": [],
      "source": [
        "class Rule:\n",
        "\n",
        "    def __init__(self, lhs, rhs, prob):\n",
        "        \"\"\"\n",
        "        Constructs a Rule.\n",
        "        A Rule takes a LHS symbol and a list/tuple of RHS symbols.\n",
        "\n",
        "        :param lhs: the LHS nonterminal\n",
        "        :param rhs: a sequence of RHS symbols (terminal or nonterminal)\n",
        "        :param prob: probability of the rule\n",
        "        \"\"\"\n",
        "\n",
        "        assert isinstance(lhs, Symbol), 'LHS must be an instance of Symbol (actually even a non-terminal but later we will expan LHS)'\n",
        "        assert len(rhs) > 0, 'If you want an empty RHS, use an epsilon Terminal EPS'\n",
        "        assert all(isinstance(s, Symbol) for s in rhs), 'RHS must be a sequence of Symbol objects'\n",
        "        if prob is not None:\n",
        "            assert 0 <= prob <= 1, 'The probability must be between 0 and 1'\n",
        "        self._lhs = lhs\n",
        "        self._rhs = tuple(rhs)\n",
        "        self._prob = prob\n",
        "\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self._lhs == other._lhs and self._rhs == other._rhs and self._prob == other._prob\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self._lhs, self._rhs, self._prob))\n",
        "\n",
        "    def __repr__(self):\n",
        "        rhs = ' '.join(str(sym) for sym in self._rhs)\n",
        "        return f\"{self._lhs} -> {rhs} ({self.prob})\"\n",
        "\n",
        "    def is_binary(self):\n",
        "        \"\"\"True if Rule is binary: A -> B C\"\"\"\n",
        "        return len(self._rhs) == 2\n",
        "\n",
        "    def is_unary(self):\n",
        "        \"\"\"True if Rule is unary: A -> w\"\"\"\n",
        "        return len(self._rhs) == 1\n",
        "\n",
        "    @property\n",
        "    def lhs(self):\n",
        "        \"\"\"Returns the lhs of the rule\"\"\"\n",
        "        return self._lhs\n",
        "\n",
        "    @property\n",
        "    def rhs(self):\n",
        "        \"\"\"Returns the rhs of the rule\"\"\"\n",
        "        return self._rhs\n",
        "\n",
        "    @property\n",
        "    def prob(self):\n",
        "        \"\"\"Returns the probability of the rule\"\"\"\n",
        "        return self._prob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4U1gI2rCGLt"
      },
      "source": [
        "Just as with `Terminal` and `Nonterminal` you can print an instance of `Rule`, you can access its attributes, and you can hash rules with containers such as dict and set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld0VMQWWCGLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fcfb8f-e655-411b-c095-70dcf6196647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S] -> [NP] [VP] (1.0)\n",
            "[NP] -> [Det] [N] (1.0)\n",
            "[N] -> 'dog' (1.0)\n",
            "[Det] -> 'the' (1.0)\n"
          ]
        }
      ],
      "source": [
        "r1 = Rule(S, [NP, VP], 1.0)\n",
        "r2 = Rule(NP, [Det, N], 1.0)\n",
        "r3 = Rule(N, [dog], 1.0)\n",
        "r4 = Rule(Det, [the], 1.0)\n",
        "r5 = Rule(VP, [walks], 1.0)\n",
        "\n",
        "print(r1)\n",
        "print(r2)\n",
        "print(r3)\n",
        "print(r4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y62yZ8I8CGLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525868e0-a551-4fa8-ad0f-5ef28c20d063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(r1.prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhEJETHgCGLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb68c87e-dda0-4a57-f0d2-d67b3ac99897"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "r1 in set([r1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTAJ2CmBCGLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e734d6e8-2d53-44d9-e760-cf7b84267a7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{[S] -> [NP] [VP] (1.0): 1, [NP] -> [Det] [N] (1.0): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "d = {r1: 1, r2: 2}\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrHaNQzKCGLw"
      },
      "source": [
        "### Grammar\n",
        "\n",
        "A `PCFG` class is a container for `Rules`. The `Rules` are stored in the `PCFG` in such a way that they can be accesed easily in different ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm6tzk7TCGLw"
      },
      "outputs": [],
      "source": [
        "class PCFG(object):\n",
        "    \"\"\"\n",
        "    Constructs a PCFG.\n",
        "    A PCFG stores a list of rules that can be accessed in various ways.\n",
        "\n",
        "    :param rules: an optional list of rules to initialize the grammar with\n",
        "    \"\"\"\n",
        "    def __init__(self, rules=[]):\n",
        "        self._rules = []\n",
        "        self._rules_by_lhs = defaultdict(list)\n",
        "        self._terminals = set()\n",
        "        self._nonterminals = set()\n",
        "        for rule in rules:\n",
        "            self.add(rule)\n",
        "\n",
        "    def add(self, rule):\n",
        "        \"\"\"Adds a rule to the grammar\"\"\"\n",
        "        if not rule in self._rules:\n",
        "            self._rules.append(rule)\n",
        "            self._rules_by_lhs[rule.lhs].append(rule)\n",
        "            self._nonterminals.add(rule.lhs)\n",
        "            for s in rule.rhs:\n",
        "                if s.is_terminal():\n",
        "                    self._terminals.add(s)\n",
        "                else:\n",
        "                    self._nonterminals.add(s)\n",
        "\n",
        "    def update(self, rules):\n",
        "        \"\"\"Add a list of rules to the grammar\"\"\"\n",
        "        for rule in rules:\n",
        "            self.add(rule)\n",
        "\n",
        "    @property\n",
        "    def nonterminals(self):\n",
        "        \"\"\"The list of nonterminal symbols in the grammar\"\"\"\n",
        "        return self._nonterminals\n",
        "\n",
        "    @property\n",
        "    def terminals(self):\n",
        "        \"\"\"The list of terminal symbols in the grammar\"\"\"\n",
        "        return self._terminals\n",
        "\n",
        "    @property\n",
        "    def rules(self):\n",
        "        \"\"\"The list of rules in the grammar\"\"\"\n",
        "        return self._rules\n",
        "\n",
        "    @property\n",
        "    def binary_rules(self):\n",
        "        \"\"\"The list of binary rules in the grammar\"\"\"\n",
        "        return [rule for rule in self._rules if rule.is_binary()]\n",
        "\n",
        "    @property\n",
        "    def unary_rules(self):\n",
        "        \"\"\"The list of unary rules in the grammar\"\"\"\n",
        "        return [rule for rule in self._rules if rule.is_unary()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._rules)\n",
        "\n",
        "    def get(self, lhs):\n",
        "        \"\"\"The list of rules whose LHS is the given symbol lhs\"\"\"\n",
        "        return self._rules_by_lhs.get(lhs, [])\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Iterator over rules (in arbitrary order)\"\"\"\n",
        "        return iter(self._rules)\n",
        "\n",
        "    def iteritems(self):\n",
        "        \"\"\"Iterator over pairs of the kind (LHS, rules rewriting LHS)\"\"\"\n",
        "        return self._rules_by_lhs.items()\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Prints the grammar line by line\"\"\"\n",
        "        lines = []\n",
        "        for lhs, rules in self.iteritems():\n",
        "            for rule in rules:\n",
        "                lines.append(str(rule))\n",
        "        return '\\n'.join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcGZAbUSCGLx"
      },
      "source": [
        "Initialize a grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIVuStsyCGLy"
      },
      "outputs": [],
      "source": [
        "G = PCFG()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVkm-al_CGLy"
      },
      "source": [
        "We can add rules individually with `add`, or as a list with `update`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-d55FW6CGLy"
      },
      "outputs": [],
      "source": [
        "G.add(r1)\n",
        "G.update([r2,r3,r4,r5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "f-3Mf4JPCGLy"
      },
      "source": [
        "We can print the grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZNR4GxqCGLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78c5113-d4a6-4d19-d348-01cc39116f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S] -> [NP] [VP] (1.0)\n",
            "[NP] -> [Det] [N] (1.0)\n",
            "[N] -> 'dog' (1.0)\n",
            "[Det] -> 'the' (1.0)\n",
            "[VP] -> 'walks' (1.0)\n"
          ]
        }
      ],
      "source": [
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpEzw7CSCGLz"
      },
      "source": [
        "We can get the set of rewrite rules for a certain LHS symbol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvJI3GIPCGLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ec82c3-b283-4aef-e9e8-5dad757c84c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[S] -> [NP] [VP] (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "G.get(S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3cghJx6CGL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081c46d0-5d45-40a9-b793-afa89b4e65ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[NP] -> [Det] [N] (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "G.get(NP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNh0XOhuCGL0"
      },
      "source": [
        "We can also iterate through rules in the grammar.\n",
        "\n",
        "Note that the following is basically counting how many rules we have in the grammar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXVqzI9lCGL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118a86a9-0d1b-4fd1-a940-32e73b48a13e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "sum(1 for r in G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jjU3krCCGL1"
      },
      "source": [
        "which can also be done in a more efficient way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vi814lRCGL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82829a6-cc5a-4e89-9d5a-ba67e5c86369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l7BmtlyCGL2"
      },
      "source": [
        "We can access the set of terminals and nonterminals of the grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9--IbP75CGL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c07e39b-8c3f-411d-cdcc-0a620f8e3d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Nonterminal('VP'), Nonterminal('Det'), Nonterminal('NP'), Nonterminal('S'), Nonterminal('N')}\n"
          ]
        }
      ],
      "source": [
        "print(G.nonterminals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MvItFKtCGL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ef68e1-f048-4a14-991a-c0109a0a42bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Terminal('dog'), Terminal('walks'), Terminal('the')}\n"
          ]
        }
      ],
      "source": [
        "print(G.terminals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q29uTBaXCGL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e30598-1e18-4f20-9430-167d1ad776cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "S in G.nonterminals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsVg9Wf2CGL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12cc685f-b4e3-43bd-831e-893232597992"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "dog in G.terminals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ojHdLHUCGL4"
      },
      "source": [
        "Finally we can easily access all the binary rules and all the unary rules in the grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv6pcFS1CGL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1762bf43-103a-4083-9337-8b5ed77cd0fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[N] -> 'dog' (1.0), [Det] -> 'the' (1.0), [VP] -> 'walks' (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "G.unary_rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYpJIx4mCGL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cab856-28f1-42db-906b-1d7948990142"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[S] -> [NP] [VP] (1.0), [NP] -> [Det] [N] (1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "G.binary_rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZdbicfrCGL5"
      },
      "source": [
        "## Visualizing a tree\n",
        "\n",
        "For the sake of legacy let's reiterate an age-old NLP schtick, the well-known example of structural ambiguity from the Groucho Marx movie, [Animal Crackers](https://youtu.be/FZUfhfHbjE4?t=1m33s) (1930):\n",
        "\n",
        "> One morning I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\n",
        "\n",
        "Let's take a closer look at the ambiguity in the phrase: _I shot an elephant in my pajamas_. The ambiguity is caused by the fact that the sentence has two competing parses represented in:\n",
        "\n",
        "    (S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\n",
        "\n",
        "and\n",
        "\n",
        "    (S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\n",
        "\n",
        "\n",
        "We can write these parses down as strings and then let NLTK turn them into trees using the NLTK `Tree` class. (See http://www.nltk.org/api/nltk.html#nltk.tree.Tree as reference for this class, if you want to know more.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDFH2wyqCGL5"
      },
      "outputs": [],
      "source": [
        "parse1 = \"(S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\"\n",
        "parse2 = \"(S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\"\n",
        "\n",
        "pajamas1 = Tree.fromstring(parse1)\n",
        "pajamas2 = Tree.fromstring(parse2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjQ_EvhHCGL5"
      },
      "source": [
        "We can then *pretty-print* these trees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSsl34LCCGL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080b6c40-f9f9-48ad-eec4-6cc51aef02ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     S                                       \n",
            "  ___|______________                          \n",
            " |                  VP                       \n",
            " |         _________|__________               \n",
            " |        VP                   PP            \n",
            " |    ____|___              ___|___           \n",
            " |   |        NP           |       NP        \n",
            " |   |     ___|_____       |    ___|_____     \n",
            " NP  V   Det        N      P  Det        N   \n",
            " |   |    |         |      |   |         |    \n",
            " I  shot  an     elephant  in  my     pajamas\n",
            "\n",
            "     S                                       \n",
            "  ___|__________                              \n",
            " |              VP                           \n",
            " |    __________|______                       \n",
            " |   |                 NP                    \n",
            " |   |     ____________|___                   \n",
            " |   |    |                NP                \n",
            " |   |    |      __________|___               \n",
            " |   |    |     |              PP            \n",
            " |   |    |     |       _______|___           \n",
            " |   |    |     |      |           NP        \n",
            " |   |    |     |      |        ___|_____     \n",
            " NP  V   Det    N      P      Det        N   \n",
            " |   |    |     |      |       |         |    \n",
            " I  shot  an elephant  in      my     pajamas\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pajamas1.pretty_print()\n",
        "pajamas2.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjAkmuXCGL7"
      },
      "source": [
        "## Parsing with CKY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8pVcXseCGL8"
      },
      "source": [
        "Let's stick with this sentence for the rest of this lab. We will use CKY to find the 'best' parse for this sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWkI8S1kCGL8"
      },
      "outputs": [],
      "source": [
        "# Turn the sentence into a list\n",
        "sentence = \"I shot an elephant in my pajamas\".split()\n",
        "# The length of the sentence\n",
        "num_words = len(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtehwdb1CGL8"
      },
      "source": [
        "A PCFG for this sentence can be found in the file `groucho-grammar-1.txt`. We read this in with the function `read_grammar_rules`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVASx2r0CGL9"
      },
      "outputs": [],
      "source": [
        "def read_grammar_rules(istream):\n",
        "    \"\"\"Reads grammar rules formatted as 'LHS ||| RHS ||| PROB'.\"\"\"\n",
        "    for line in istream:\n",
        "        line = line.strip()\n",
        "        if not line: continue\n",
        "        fields = line.split('|||')\n",
        "        if len(fields) != 3:\n",
        "            raise ValueError(f\"Three fields were expected: {fields}\")\n",
        "        lhs = fields[0].strip()\n",
        "\n",
        "        if lhs.startswith('[') and lhs.endswith(']'):\n",
        "            lhs = Nonterminal(lhs[1:-1])\n",
        "        else:\n",
        "            raise ValueError(f\"LHS must be a non-terminal: {fields}\")\n",
        "        rhs = fields[1].strip().split()\n",
        "        new_rhs = []\n",
        "        for r in rhs:\n",
        "            if r.startswith('[') and r.endswith(']'):\n",
        "                r = Nonterminal(r[1:-1])\n",
        "            else:\n",
        "                r = Terminal(r)\n",
        "            new_rhs.append(r)\n",
        "\n",
        "        prob = float(fields[2].strip())\n",
        "        yield Rule(lhs, new_rhs, prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UP_-I5XCGL9",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aad2eed-ef6e-41f0-a558-03699657cf2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The grammar:\n",
            " [S] -> [NP] [VP] (1.0)\n",
            "[PP] -> [P] [NP] (1.0)\n",
            "[NP] -> [Det] [N] (0.2)\n",
            "[NP] -> [Det] [NP] (0.3)\n",
            "[NP] -> [N] [PP] (0.3)\n",
            "[NP] -> 'I' (0.2)\n",
            "[VP] -> [V] [NP] (0.4)\n",
            "[VP] -> [VP] [PP] (0.6)\n",
            "[Det] -> 'an' (0.6)\n",
            "[Det] -> 'my' (0.4)\n",
            "[N] -> 'elephant' (0.5)\n",
            "[N] -> 'pajamas' (0.5)\n",
            "[V] -> 'shot' (1.0)\n",
            "[P] -> 'in' (1.0)\n"
          ]
        }
      ],
      "source": [
        "# Read in the grammar\n",
        "with open('groucho-grammar-1.txt') as F:\n",
        "    grammar = PCFG(read_grammar_rules(F))\n",
        "print(\"The grammar:\\n\", grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRecCE1RCGL-"
      },
      "source": [
        "We will also need the following two dictionaries: `nonterminal2index` mapping from nonterminals to integers (indices); and its inverse, an `index2nonterminal` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjPcYJQuCGL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b6dab2-80ee-40d1-abf5-271bc7c5e966"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Nonterminal('Det'): 0,\n",
              " Nonterminal('N'): 1,\n",
              " Nonterminal('NP'): 2,\n",
              " Nonterminal('P'): 3,\n",
              " Nonterminal('PP'): 4,\n",
              " Nonterminal('S'): 5,\n",
              " Nonterminal('V'): 6,\n",
              " Nonterminal('VP'): 7}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "num_nonterminals = len(grammar.nonterminals)\n",
        "\n",
        "# Make a nonterminal2index and a index2nonterminal dictionary\n",
        "n2i = defaultdict(lambda: len(n2i))\n",
        "i2n = dict()\n",
        "\n",
        "# sort nonterminals to make the mapping deterministic\n",
        "for nt in sorted(grammar.nonterminals):\n",
        "    i2n[n2i[nt]] = nt\n",
        "\n",
        "# Stop defaultdict behavior of n2i\n",
        "n2i = dict(n2i)\n",
        "\n",
        "n2i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x_4Mb1xCGL-"
      },
      "source": [
        "### The charts\n",
        "\n",
        "Now we are ready to introduce the chart datastructures. We need a chart to store the **scores** and a chart to store the **backpointers**.\n",
        "\n",
        "Both of these will be 3-dimensional numpy arrays: one named `score` holding the probabilities of intermediate results; one named `back` to store the backpointers in. We will use the following indexing convention for these charts:\n",
        "\n",
        "* Format of the chart holding the **scores** `score[A][begin][end] = probability`.\n",
        "This is interpreted as the probability of the constituent between `begin:end` being parsed with `A` as its root.      \n",
        "         \n",
        "* Format of the chart holding the **backpointers** `back[A][begin][end] = (split, B, C)`.\n",
        "This is interpreted as the constituent `begin:end` can be combined with a rule `A -> B C` where `begin:split` is `B` and `split:end` is `C`.\n",
        "\n",
        "This indexing convention is convenient for printing. See what happens when we print `back` below: we get `num_nonterminal` slices, each a numpy array of shape `[n_words+1, n_words+1]`. This is easier to read than the format `score[i][j][A]`.\n",
        "\n",
        "**[Note]** Here we pretended `A` is both the nonterminal as well as the index. In our implementation `A` will be the nonterminal and the index for `A` will be `n2i[A]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCtGbwpQCGL-"
      },
      "source": [
        "Let's show you what we mean:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqNdJjfrCGL-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# A numpy array zeros\n",
        "score = np.zeros((num_nonterminals,\n",
        "                  num_words + 1,\n",
        "                  num_words + 1))\n",
        "\n",
        "# A numpy array that can store arbitrary data (we set dtype to object)\n",
        "back = np.zeros((num_nonterminals,\n",
        "                 num_words + 1,\n",
        "                 num_words + 1), dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0YJ227uCGL-"
      },
      "source": [
        "The following illustrates the way you will use the `back` chart. In this example, your parser recognized that the entire sequence is S while the words between 0 and 2 form NP, and the words between 2 and the end of the sentence form VP (and nothing else yet):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7KOKnTuCGL_",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1b2a57-0236-4ab6-dd2e-a484e055dc94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, (2, Nonterminal('NP'), Nonterminal('VP'))],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Illustration of the backpointer array\n",
        "back[n2i[S]][0][-1] = (2,NP,VP)\n",
        "back"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkUx3Mc5CGL_"
      },
      "source": [
        "## Ex1 [40pt] CKY parsing\n",
        "\n",
        "Implement the **CKY** algorithm. Follow the pseudo-code given in the lecture-slides (or alternatively in J&M). The code must comply to the following:\n",
        "\n",
        "* The function `cky` takes a sentence (list of words), a grammar (an instance of PCFG), and a n2i non-terminals-to-index dictionary.\n",
        "* The function `cky` returns the filled-in score-chart and backpointer-chart, following the format established above.\n",
        "* No global variables should be accessed from the body of the function (except for the predefined classes).\n",
        "\n",
        "**[Hint]** This is the moment to make good use of the methods of the classes `PCFG`, `Rule`, `Nonterminal`, and `Terminal`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kq23wsvCGL_"
      },
      "outputs": [],
      "source": [
        "def cky(sentence, grammar, n2i):\n",
        "    \"\"\"\n",
        "    The CKY algorithm.\n",
        "\n",
        "    :param sentence: a list of words\n",
        "    :param grammar: an instance of the class PCFG\n",
        "    :param n2i: a dictionary mapping from Nonterminals to indices\n",
        "    :return score: the filled in scores chart\n",
        "    :return back: the filled in backpointers chart\n",
        "    \"\"\"\n",
        "    num_words = len(sentence)\n",
        "    num_nonterminals = len(grammar.nonterminals)\n",
        "\n",
        "    # A numpy array to store the scores of intermediate parses\n",
        "    score = np.zeros((num_nonterminals,\n",
        "                  num_words + 1,\n",
        "                  num_words + 1))\n",
        "\n",
        "    # A numpy array to store the backpointers\n",
        "    back = np.zeros((num_nonterminals,\n",
        "                     num_words + 1,\n",
        "                     num_words + 1), dtype=object)\n",
        "    print(back)\n",
        "\n",
        "    ## YOUR CODE HERE ##\n",
        "    #the code below follows the slides from week 4: 14, 15, and 16\n",
        "\n",
        "    for i, word in enumerate(sentence):\n",
        "      word = Terminal(word)\n",
        "      for r in grammar.rules:\n",
        "        if word == r.rhs[0]:\n",
        "          score[n2i[r.lhs]][i][i+1] = (r.prob)\n",
        "\n",
        "    for span in range(2, num_words + 1):\n",
        "      for begin in range(0, num_words - span + 1):\n",
        "        end = begin + span\n",
        "        for split in range(begin+1, end):\n",
        "          for r in grammar.binary_rules:\n",
        "            left_nodes = [n for n in r.lhs]\n",
        "            #I am stuck here\n",
        "\n",
        "\n",
        "\n",
        "     return score, back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdyvogQICGMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca73c8b3-4857-4c33-f7fb-10b0491aa557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]]\n"
          ]
        }
      ],
      "source": [
        "# Run CKY\n",
        "score, back = cky(sentence, grammar, n2i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-RR3hKxCGMA"
      },
      "source": [
        "### Check your CKY\n",
        "\n",
        "Use the code in the following two cell to check your `cky` implementation.\n",
        "\n",
        "Take the Nonterminal `S` to inspect your filled in score and backpointer charts. **Leave the code in this cell unchanged.** We will use this to evaluate the corectness of your cky function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBvi4nElCGMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59800430-e7c2-40d0-daee-2912a06b1e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The whole slice for nonterminal S:\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]] \n",
            "\n",
            "The score in cell (S, 0, num_words), which is the probability of the best parse:\n",
            "0.0 \n",
            "\n",
            "The backpointer in cell (S, 0, num_words):\n",
            "0 \n",
            "\n",
            "[[0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# TEST EX1.1\n",
        "### Don't change the code in this cell ###\n",
        "\n",
        "S = Nonterminal('S')\n",
        "\n",
        "print('The whole slice for nonterminal S:')\n",
        "print(score[n2i[S]], \"\\n\")\n",
        "\n",
        "print('The score in cell (S, 0, num_words), which is the probability of the best parse:')\n",
        "print(score[n2i[S]][0][num_words], \"\\n\")\n",
        "\n",
        "print('The backpointer in cell (S, 0, num_words):')\n",
        "print(back[n2i[S]][0][num_words], \"\\n\")\n",
        "\n",
        "print(back[n2i[S]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFo5ehEACGMC"
      },
      "source": [
        "## Ex2 [20pt] Recovering a tree\n",
        "\n",
        "Write the function `build_tree` that reconstructs the parse from the backpointer table. This is the function that is called in the return statement of the [pseudo-code](https://web.stanford.edu/~jurafsky/slp3/C.pdf#page=6) in Jurafsky and Martin.\n",
        "\n",
        "**[Note]** We have no pseudocode for you here: you must come up with your own implementation. However we do provide you with the expected output so that you can at least partially test your code.\n",
        "\n",
        "Here is some additional advice:\n",
        "\n",
        "* Use recursion - that is write your function in a recursive way.  \n",
        "What is the base case? Hint: $A \\to w$.  \n",
        "What is the recursive case? Hint: $A \\to B\\; C$.\n",
        "    \n",
        "    \n",
        "* Use the additional class `Span` that we introduce below for the symbols in your recovered rules. Read the documentation in the `Span` class for its usage.\n",
        "    \n",
        "    \n",
        "* In order to use the function `make_nltk_tree` (which we provide and that turns a `derivation` into an NLTK tree so that you can draw it), your function must return the <font color=\"red\">**list of rules in derivation ordered [depth-first](https://en.wikipedia.org/wiki/Depth-first_search)**</font>. If you write your function recursively such order can be achieved easily.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyYrjUP9CGMC"
      },
      "source": [
        "The following class will be very useful in your solution for the function `build_tree`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty0jbFeuCGMD"
      },
      "outputs": [],
      "source": [
        "class Span(Symbol):\n",
        "    \"\"\"\n",
        "    A Span indicates that symbol was recognized between begin and end.\n",
        "\n",
        "    Example:\n",
        "        Span(Terminal('the'), 0, 1)\n",
        "            This means: we found 'the' in the sentence between 0 and 1\n",
        "        Span(Nonterminal('NP'), 4, 8) represents NP:4-8\n",
        "            This means: we found an NP that covers the part of the sentence between 4 and 8\n",
        "\n",
        "    Thus, Span holds a Terminal or a Nonterminal and wraps it between two integers.\n",
        "    This makes it possible to distinguish between two instances of the same rule in the derivation.\n",
        "    Example:\n",
        "        We can find that the rule NP -> Det N is used twice in the parse derivation. But that in the first\n",
        "        case it spans \"an elephant\" and in the second case it spans \"my pajamas\". We want to distinguis these.\n",
        "        So: \"an elephant\" is covered by [NP]:2-4 -> [Det]:2-3 [N]:3-4\n",
        "            \"my pajamas\" is covered by [NP]:5-7 -> [Det]:5-6 [N]:6-7\n",
        "\n",
        "    Internally, we represent spans with tuples of the kind (symbol, start, end).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol, start, end):\n",
        "        assert isinstance(symbol, Symbol), f\"A span takes an instance of Symbol, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "        self._start = start\n",
        "        self._end = end\n",
        "\n",
        "    def is_terminal(self):\n",
        "        # a span delegates this to an underlying symbol\n",
        "        return self._symbol.is_terminal()\n",
        "\n",
        "    def obj(self):\n",
        "        \"\"\"The underlying python tuple (Symbol, start, end)\"\"\"\n",
        "        return (self._symbol, self._start, self._end)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Prints Symbol surrounded with begin and end (purely aesthetics)\"\"\"\n",
        "        return f\"{self._start}:{self._symbol}:{self._end}\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Span({self._symbol!r}, {self._start!r}, {self._end!r})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self._symbol, self._start, self._end))\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol and self._start == other._start and self._end == other._end\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW5SsW6sCGMD"
      },
      "source": [
        "Example usage of `Span`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwn43NFYCGME"
      },
      "outputs": [],
      "source": [
        "span_S = Span(S, 0, 10)\n",
        "print(span_S)\n",
        "span_S = Span(dog, 4, 5)\n",
        "print(span_S)\n",
        "\n",
        "spanned_rule = Rule(Span(NP, 2, 4), [Span(Det, 2, 3), Span(NP, 3, 4)], prob=None)\n",
        "print(spanned_rule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E4CFhArSpLL"
      },
      "source": [
        "Your final derivation should look like this:\n",
        "\n",
        "```\n",
        "[0:[S]:7 -> 0:[NP]:1 1:[VP]:7 (None),\n",
        " 0:[NP]:1 -> 0:'I':1 (None),\n",
        " 1:[VP]:7 -> 1:[VP]:4 4:[PP]:7 (None),\n",
        " 1:[VP]:4 -> 1:[V]:2 2:[NP]:4 (None),\n",
        " 1:[V]:2 -> 1:'shot':2 (None),\n",
        " 2:[NP]:4 -> 2:[Det]:3 3:[N]:4 (None),\n",
        " 2:[Det]:3 -> 2:'an':3 (None),\n",
        " 3:[N]:4 -> 3:'elephant':4 (None),\n",
        " 4:[PP]:7 -> 4:[P]:5 5:[NP]:7 (None),\n",
        " 4:[P]:5 -> 4:'in':5 (None),\n",
        " 5:[NP]:7 -> 5:[Det]:6 6:[N]:7 (None),\n",
        " 5:[Det]:6 -> 5:'my':6 (None),\n",
        " 6:[N]:7 -> 6:'pajamas':7 (None)]\n",
        " ```\n",
        "\n",
        "(Note that the rule probabilities are set to `None`. These are not saved in the backpointer chart so cannot be retrieved at the recovering stage. They also don't matter at this point, so you can set them to `None`.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3tD8G4MCGMF"
      },
      "source": [
        "### build_tree function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5iPPQ9kCGMF"
      },
      "outputs": [],
      "source": [
        "def build_tree(back, sentence, root, n2i, begin=0, end=None):\n",
        "    \"\"\"\n",
        "    Reconstruct the viterbi parse from a filled-in backpointer chart.\n",
        "    The function takes detailed arguments to be easily used in a recursive way.\n",
        "\n",
        "    It returns a list called derivation which holds the rules over Spans.\n",
        "    In order to use the function make_nltk_tree for the output,\n",
        "    you must make sure that the order in derivation follows the depth-first order (!!!).\n",
        "\n",
        "    :param back: a backpointer chart of shape [num_nonterminals, num_words+1, num_words+1]\n",
        "    :param sentence: a list of words\n",
        "    :param root: the root symbol of the tree: usually Nonterminal('S')\n",
        "    :param n2i: the dictionary mapping from Nonterminals to indices\n",
        "    :param begin: index that marks the start of the target segment of the sentence\n",
        "    :param end: index that marks the end of the target segment of the sentence\n",
        "    :param n2i: the dictionary mapping from Nonterminals to indices\n",
        "    :return derivation: a derivation: a list of Rules with Span symbols that generate the Viterbi tree.\n",
        "                        The list should be ordered depth first!\n",
        "    \"\"\"\n",
        "    if end is None: end = len(sentence)\n",
        "    assert isinstance(end, int), \"when end argument is specified, it needs to be an integer\"\n",
        "    derivation = []\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "    return derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C-x98b5CGMG"
      },
      "source": [
        "Get your derivation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZCWB9n8CGMG"
      },
      "outputs": [],
      "source": [
        "derivation = build_tree(back, sentence, S, n2i)\n",
        "derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7hKnXenUcyk"
      },
      "source": [
        "### Draw the tree\n",
        "\n",
        "Turn the derivation into an NLTK tree:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKPgJ9q5CGMG"
      },
      "outputs": [],
      "source": [
        "def make_nltk_tree(derivation):\n",
        "    \"\"\"\n",
        "    Return a NLTK Tree object based on the derivation\n",
        "    (list or tuple of Rules)\n",
        "    \"\"\"\n",
        "    d = defaultdict(None, ((r.lhs, r.rhs) for r in derivation))\n",
        "\n",
        "    def make_tree(lhs):\n",
        "        return Tree(str(lhs), (str(child) if child not in d else make_tree(child) for child in d[lhs]))\n",
        "\n",
        "    return make_tree(derivation[0].lhs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhh7YJLMUoIa"
      },
      "source": [
        "If you give the derivation to the function `make_nltk_tree` and let NLTK draw it, then you get this tree:\n",
        "\n",
        "```\n",
        "          0:[S]:7                                                                              \n",
        "    _________|_______________________________                                                   \n",
        "   |                                      1:[VP]:7                                             \n",
        "   |                     ____________________|_____________________                             \n",
        "   |                 1:[VP]:4                                   4:[PP]:7                       \n",
        "   |          __________|________                         _________|________                    \n",
        "   |         |                2:[NP]:4                   |               5:[NP]:7              \n",
        "   |         |           ________|___________            |          ________|___________        \n",
        "0:[NP]:1  1:[V]:2   2:[Det]:3             3:[N]:4     4:[P]:5  5:[Det]:6             6:[N]:7   \n",
        "   |         |          |                    |           |         |                    |       \n",
        "0:'I':1  1:'shot':2  2:'an':3          3:'elephant':4 4:'in':5  5:'my':6          6:'pajamas':7\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8KwEzfKNHsG"
      },
      "outputs": [],
      "source": [
        "# TEST EX1.2\n",
        "tree = make_nltk_tree(derivation)\n",
        "tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KpnoxfjCGMH"
      },
      "source": [
        "## That's it!\n",
        "\n",
        "Congratulations, you have made it to the end of the lab.\n",
        "\n",
        "**Make sure all your cells are executed so that all your answers are there. Then, continue if you're interested!**\n",
        "\n",
        "----\n",
        "\n",
        "## Optional\n",
        "\n",
        "If you managed to get your entire CKY-parser working and have an appetite for more, it might be fun to try it on some more sentences and grammars. Give the grammars below a try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQXFftl-CGMH"
      },
      "source": [
        "### Alternative Groucho-grammar\n",
        "\n",
        "If you change the probabilities in the grammar, you'll get a different parse as the most likely one. Compare `groucho-grammar-1.txt` with `groucho-grammar-2.txt` and spot the difference in probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmKzOKOrCGMH"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQvNMXcpCGMI"
      },
      "source": [
        "### The man with the telescope\n",
        "\n",
        "Another ambiguous sentence:\n",
        "\n",
        "> I saw the man on the hill with the telescope.\n",
        "\n",
        "A grammar for this sentence is specified in the file `telescope-grammar.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saH1dFIkCGMI"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qVlbZcDiYag"
      },
      "source": [
        "# Acknowledgments\n",
        "\n",
        "Most of this lab was developed in collaboration with Joost Bastings.  \n",
        "Later it was revised by Tejaswini Deoskar.  \n",
        "The recent updates by Lasha Abzianidze make the notebook more streamlined and foolproof from the grading and the large course perspectives."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}